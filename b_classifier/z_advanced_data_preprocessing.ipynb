{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333caa03-0d5d-44c1-a04e-bed8e0fa2399",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "\n",
    "#### StandardScaler()\n",
    "- 데이터의 평균을 0, 분산을 1이 되도록, 표준 정규분포를 따르게 하는 스케일링\n",
    "- ±1.96을 벗어나면 이상치로 판단한다.\n",
    "- <code>from sklearn.preprocessing import StandardScaler</code>\n",
    "\n",
    "#### MinMaxScaler()\n",
    "- 데이터가 0~1 사이에 위치하도록 최소값은 0, 최대값을 1로 변환한다.\n",
    "- 서로 다른 단위의 feature끼리 비교가 가능해진다.\n",
    "- <code>from sklearn.preprocessing import MinMaxScaler</code>\n",
    "\n",
    "#### MaxAbsScaler()\n",
    "- 모든 값을 -1~1 사이에 위치하도록, 절대값의 최소값은 0, 최대값은 1이 되도록 변환한다.\n",
    "- 양의 방향에 대한 단위뿐 아니라 음의 방향에 대한 단위까지 스케일링하고자 할 때 사용한다.\n",
    "- <code>from sklearn.preprocessing import MaxAbsScaler</code>\n",
    "\n",
    "#### 로그변환 (Log transformation)\n",
    "- 왜도와 첨도를 가진 변수를 정규분포에 가깝게 만들어준다. 큰 수치를 같은 비율의 작은 수치로 변환한다.\n",
    "- <code>np.log1p(df['col'])</code>\n",
    "- 원래 값으로 전환하고자 할 때 지수를 취해준다.\n",
    "- <code>np.expm1(df['col'])</code>\n",
    "\n",
    "#### 언더 샘플링 (Under sampling)\n",
    "- 불균형한 데이터 세트에서 높은 비율을 차지하던 클래스의 데이터 수를 줄임으로써 데이터 불균형을 해소한다.\n",
    "- 학습에 사용되는 전체 데이터 수를 급격하게 감소시켜 오히려 성능이 떨어질 수 있다.\n",
    "\n",
    "<img src=\"./images/under_sampling.png\" width=\"400px\" style=\"margin-left: 20px;\">\n",
    "\n",
    "#### 오버 샘플링 (Over sampling)\n",
    "- 불균형한 데이터 세트에서 낮은 비율 클래스의 데이터 수를 늘림으로써 데이터 불균형을 해소한다.\n",
    "- 오버 샘플링의 대표적인 방법에는 SMOTE(Synthetic Minority Over-sampling Technique)가 있다.\n",
    "\n",
    "<img src=\"./images/over_sampling.png\" width=\"400px\" style=\"margin-left: 20px;\">\n",
    "\n",
    "#### SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "- 반드시 학습 데이터 세트만 오버 샘플링 해야 한다.\n",
    "- 검증 혹은 테스트 데이터 세트를 오버 샘플링하는 경우 원본 데이터가 아닌 데이터에서 검증되기 때문에 올바른 검증이 되지 않는다.\n",
    "- 낮은 비율 클래스 데이터들의 최근접 이웃을 이용하여 새로운 데이터를 생성한다.\n",
    "- 동일한 데이터를 복제하는 것은 의미가 없기 때문에 일정한 거리를 떨어진 위치에 데이터를 생성하기 위함이다.\n",
    "- 오버 샘플링을 하게 되면 양성으로 예측하는 비율이 높아지기 때문에 정밀도가 감소하고 재현율이 증가한다.\n",
    "- 오버 샘플링을 정확히 수행하기 위해서는 category 타입을 사용하는 것보다 직접 인코딩해주는 것이 좋다.\n",
    "\n",
    "<img src=\"./images/smote.png\" width=\"650px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2d069f-5286-499e-81ba-119bfce32458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features, targets = c_df.iloc[:, :-1], c_df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(features, targets, stratify=targets, test_size=0.2, random_state=124)\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f01e0-7f17-4640-b430-4621765e45fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오버 샘플링\n",
    "# conda install -c conda-forge imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=124)\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f'SMOTE 적용 전: \\n{y_train.value_counts()}')\n",
    "print(f'SMOTE 적용 후: \\n{y_train_over.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263b0246-dfce-44d8-8698-1200708ed443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
